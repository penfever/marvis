{
  "dataset_name": "convai2_inferred",
  "description": "This dataset is part of a larger effort to study and classify gender bias in conversational AI systems. It contains persona-based conversations from the ConvAI2 competition, specifically annotated and analyzed for gender-related attributes and biases. The data represents conversations where personas contain gender-identifiable information, which has been annotated both manually and through automated classification.",
  "original_source": {
    "creator": "Emily Dinan, Angela Fan, Ledell Wu, Jason Weston, Douwe Kiela, Adina Williams",
    "institution": "Facebook AI Research (FAIR)",
    "date": "2020",
    "publication": "Multi-Dimensional Gender Bias Classification (EMNLP 2020)"
  },
  "columns": [
    {
      "name": "0",
      "semantic_description": "Likely represents text features or embeddings from the conversation context",
      "data_type": "numeric (encoded representation)"
    },
    {
      "name": "1",
      "semantic_description": "Likely represents speaker (AS) gender-related features",
      "data_type": "numeric (encoded representation)"
    },
    {
      "name": "2",
      "semantic_description": "Likely represents addressee (TO) gender-related features",
      "data_type": "numeric (encoded representation)"
    },
    {
      "name": "3",
      "semantic_description": "Likely represents ABOUT classification features",
      "data_type": "numeric (encoded representation)"
    },
    {
      "name": "4",
      "semantic_description": "Additional contextual or derived features from the conversation",
      "data_type": "numeric (encoded representation)"
    }
  ],
  "target_description": {
    "name": "ternary_score",
    "meaning": "A measure of gender bias classification on a three-point scale, likely representing neutral, biased, or strongly biased classifications",
    "units": "Categorical/Numerical score",
    "range": "Likely [0,2] or [-1,1], representing different levels of gender bias"
  },
  "dataset_history": "This dataset was created as part of research into gender bias in conversational AI systems, specifically using the ConvAI2 competition data. The original ConvAI2 dataset contained persona-based conversations, which were then annotated for gender-related attributes. The researchers used both manual annotation and automated classification to identify gender biases in the conversations. This work was part of a larger effort to understand and address bias in AI systems.",
  "inference_notes": "Important considerations include:\n1. The dataset uses inferred labels for some gender classifications where explicit information wasn't available\n2. The feature names are anonymized (0-4), suggesting possible preprocessing or transformation of the original text data\n3. The ternary classification system may simplify more complex gender bias phenomena\n4. The dataset focuses on English language conversations and Western gender concepts\n5. Bias in the original annotation process or automated classification system may affect the reliability of labels\n6. The large number of instances (147,040) suggests automated or semi-automated labeling processes were used",
  "_metadata": {
    "task_id": 363387,
    "generated_at": "2025-06-22T08:28:44.721454",
    "generator": "generate_openml_semantic_info.py",
    "claude_model": "claude-3-5-sonnet-20241022"
  }
}